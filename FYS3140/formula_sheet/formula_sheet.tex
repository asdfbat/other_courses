\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc,url}
\usepackage{parskip}
\usepackage{lmodern}
\usepackage{microtype}
\usepackage{verbatim}
\usepackage{amsmath, amssymb}
\usepackage{tikz}
\usepackage{physics}
\usepackage{mathtools}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{listings}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{float}
\usepackage{hyperref}
\usepackage{tabularx}
\usepackage{siunitx}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{framed}
\usepackage{fancyvrb}
\usepackage{xcolor}
\usepackage{titlesec} % For title spacing.
\usepackage[a4paper, margin=0.2cm]{geometry}

\renewcommand{\baselinestretch}{1}
\renewcommand{\b}{\textbf}
\renewcommand{\exp}{e^}

\newcommand{\infint}{\int_{-\infty}^{\infty}}
\newcommand{\zeroinfint}{\int_{0}^{\infty}}

\newcommand{\infsum}{\sum_{n=-\infty}^{\infty}}
\newcommand{\zeroinfsum}{\sum_{n=0}^{\infty}}
\newcommand{\oneinfsum}{\sum_{n=1}^{\infty}}

%\newcommand{\holine}{\rule{286pt}{1pt}}
% \newcommand{\Holine}{\rule{286pt}{3pt}}

\newcommand{\holine}[1][\medskipamount]{\par\vspace*{\dimexpr-\parskip-\baselineskip+#1}\noindent\rule{\linewidth}{1pt}\par\vspace*{\dimexpr-\parskip-.5\baselineskip+#1}}

\newcommand{\Holine}[1][\medskipamount]{\par\vspace*{\dimexpr-\parskip-\baselineskip+#1}\noindent\rule{\linewidth}{3pt}\par\vspace*{\dimexpr-\parskip-.5\baselineskip+#1}}


\newcommand{\half}{\frac{1}{2}}


% Colorcoding. First for inside equations, second for text.
% Yellow for "problem".
\newcommand{\yl}[1]{\colorbox{yellow}{$\displaystyle #1$}}
\newcommand{\yll}{\colorbox{yellow}}
% Green for "solution".
\newcommand{\gr}[1]{\colorbox{green}{$\displaystyle #1$}}
\newcommand{\grr}{\colorbox{green}}
% Blue for "additional info".
\newcommand{\bl}[1]{\colorbox{cyan}{$\displaystyle #1$}}
\newcommand{\bll}{\colorbox{cyan}}


\setlength{\columnsep}{0.4cm}
\setlength{\columnseprule}{0.06cm}
\setlength{\FrameSep}{0.2cm}

% Setting section spacing
\titlespacing\part{0pt}{0pt plus 6pt}{0pt}
\titlespacing\section{0pt}{0pt plus 6pt}{0pt}
\titlespacing\subsection{0pt}{0pt plus 6pt}{0pt}
\titlespacing\subsubsection{0pt}{0pt plus 6pt}{0pt}




\begin{document}
\begin{multicols}{2}


\part*{Usefull Shit}

\subsection*{Taylor Expansions}
\[
    f(z) = \zeroinfsum \frac{f^{(n)}(z_0)}{n!}(z-z_0)^n
\]
\textbf{Around 0:}
\[
    \exp{x} = \sum_{n=0}^\infty \dfrac{x^n}{n!} \quad\quad\quad
    \frac{1}{1-x} = \sum_{n=0}^\infty x^n
\]
\[
    \sin{x} = \sum_{n=0}^\infty \dfrac{(-1)^n}{(2n+1)!}x^{2n+1} \quad\quad
    \cos{x} = \sum_{n=0}^\infty \dfrac{(-1)^n}{(2n)!}x^{2n}
\]


\holine
\subsection*{Random shit I always forget}
\[
    c \ln{x} = \ln{x^c} \quad\quad\quad \dv{x}\ln{x} = \frac{1}{x}
\]
\[
    x = \frac{-b\pm \sqrt{b^2 - 4ac}}{2a}
\]
\[
    \dv{x}\qty[\dfrac{u(x)}{v(x)}] = \dfrac{u'(x)v(x) - u(x)v'(x)}{v(x)^2}
\]
\[
    \int (uv') = uv - \int(u'v)
\]


\holine
\subsection*{Trigenometric Identities}
\[
    \exp{\pm i x} = \cos{x} \pm i\sin{x} \\
\]
\[
    \cos{x} = \half \qty(\exp{ix} + \exp{-ix}) \quad\quad
    \sin{x} = \frac{1}{2i}\qty(\exp{ix} - \exp{-ix})
\]
\[
    \sinh{z} = \half\qty(\exp{z}-\exp{-z}) \quad\quad \cosh{z} = \half\qty(\exp{z}+\exp{-z})
\]



% ████████╗███████╗███╗   ██╗███████╗ ██████╗ ██████╗ ███████╗
% ╚══██╔══╝██╔════╝████╗  ██║██╔════╝██╔═══██╗██╔══██╗██╔════╝
%    ██║   █████╗  ██╔██╗ ██║███████╗██║   ██║██████╔╝███████╗
%    ██║   ██╔══╝  ██║╚██╗██║╚════██║██║   ██║██╔══██╗╚════██║
%    ██║   ███████╗██║ ╚████║███████║╚██████╔╝██║  ██║███████║
%    ╚═╝   ╚══════╝╚═╝  ╚═══╝╚══════╝ ╚═════╝ ╚═╝  ╚═╝╚══════╝

\subsection*{Tensors}
\[
    A^{-1}A = \mathcal{I} \quad\quad A_T = A_{ij}^T = A_{ji}
    AB = A_{ij}B_{jk}
\]
\[
    \det{A} = \det{A^T} \quad\quad \det{AB} = \det{A}\det{B}
\]
Rotation matrices are orthogonal, such that $\gr{A^T = A^{-1}}$.

Transformational matrices from a coordinate system $\b{e}'$ to $\b{e}$ is given as $A_{ij} = e'_i \cdot e_i$

\[
    y_i = A_{ij}x_j =
    \begin{pmatrix}
        A_{11} & A_{12} & A_{13} \\
        A_{21} & A_{22} & A_{23} \\
        A_{31} & A_{32} & A_{33}
    \end{pmatrix}
    \begin{pmatrix}
        x_1 \\
        x_2 \\
        x_3
    \end{pmatrix}
\]

\[
    x_j = A_{ji}y_i = A^Ty
\]

Transformation of a higher order tensor:
\[
    T'_{\alpha\beta\gamma\delta} = A_{\alpha i}A_{\beta j}A_{\gamma k}A_{\delta l}T_{ijkl}
\]
where $A$ is the transformation matrix.


\[
    (\b{B}\times\b{C})_i = \epsilon_{ijk}B_jC_k
\]

\holine
\subsection*{Dirac Delta \& Levi-Civita}
\[
    \delta_{ij} = \begin{cases}
    1 &\text{if} \quad i=j \\
    0 &\text{else}
    \end{cases}
    \quad\quad
    \epsilon_{ijk} = \begin{cases}
    1 &\text{if} \quad i,j,k \ \text{in order} \\
    -1 &\text{if} \quad i,j,k \ \text{not in order} \\
    0 &\text{else}
    \end{cases}
\]

\[
    \infint \delta(x-a)f(x)\dd{x} = f(a)
\]







%  ██████╗ ██████╗ ███╗   ███╗██████╗ ██╗     ███████╗██╗  ██╗
% ██╔════╝██╔═══██╗████╗ ████║██╔══██╗██║     ██╔════╝╚██╗██╔╝
% ██║     ██║   ██║██╔████╔██║██████╔╝██║     █████╗   ╚███╔╝ 
% ██║     ██║   ██║██║╚██╔╝██║██╔═══╝ ██║     ██╔══╝   ██╔██╗ 
% ╚██████╗╚██████╔╝██║ ╚═╝ ██║██║     ███████╗███████╗██╔╝ ██╗
%  ╚═════╝ ╚═════╝ ╚═╝     ╚═╝╚═╝     ╚══════╝╚══════╝╚═╝  ╚═╝
\Holine
\part*{Complex analysis}
\subsection*{Usefull shit}

\begin{itemize}
    \item \bll{Positively oriented} contour integrals are counter-clockwise.
    \item $\yl{(z-z_0)<R}$ means all complex numbers within radius $R$ of $z_0$ in the complex field.
    \item In many functions, the order of it's pole is very obvious. i.e $1/(z-3)$ is a first order pole at $z=3$, and $1/(z+2i)^3$ is a third order pole at $z=-2i$.
    \item When encountered by a fraction with $i$ in the denominator, multiply by the \bll{complex conjugate} to move the $i$ upstairs. (i.e. $1/(3+2i)$, multiply by $(3-2i)$). In general:
    \[
        (x+iy)(x-iy) = (x^2 + y^2)
    \]
    \item When showing that a contour integral is 0, an \bll{upper-bound estimate} is often usefull.
\end{itemize}

\[
    \ln{z} = \ln|z| + i\theta, \quad\quad \theta\in[-\pi,\, \pi]
\]



\holine
\subsection*{Polar representation and roots}
\[
    z = x + iy = r(\cos(\theta) + i\sin(\theta)) = r\exp{i\theta}
\]

\textbf{Powers of z:}
\[
    z^n = (r\exp{i\theta})^n = r^n\exp{in\theta} = \cos(n\theta) + i \sin(n\theta)
\]

\textbf{Roots of z:} 
\[\gr{
    z^{1/n} = r^{1/n}\exp{i(\theta + 2\pi k)/n}, \quad\quad\quad k\in 0,1,2,...,n-1
}\]
$z^{1/n}$ has $n$ roots, spread evenly in a circle in the complex plane.



\holine
\subsection*{Complex Series}
The complex sequence
\[
    \{z_n\} = \{z_1, z_2, z_3, ...\}
\]
converges if both the real and imaginary parts of $z_n$ approaches zero for large $n$.

The complex series
\[
    s_n = \sum_{k=1}^n z_k
\]
converges if $z_k$ converges.

\textbf{Ratio test:}
if $\frac{z_{n+1}}{z_n} \leq 1$ for large $n$, then $z_k$ converges.


\holine
\subsection*{Complex Power Series}
\[
    \sum_{n=0}^\infty a_n(z-z_0)^n
\]
Around a point $z_0$, series converges for the area of $z$ where
\[
    |z-z_0| < \lim_{n\rightarrow\infty} \qty|\frac{a_n}{a_{n+1}}| = R
\]
where $R$ is called the \textit{radius of convergence}.


\holine
\subsection*{Analytic Functions}
Analytic functions are special in that they treat $z=x+iy$ as a single unit, i.e. respect the complex structure.

If the \bll{output can be expressed} solely in $z$ (without $x$, $y$ or $z^*$), the function is analytic. Remember that $x = \half (z+z^*)$ and $y=\frac{1}{2i}(z-z^*)$.

An function analytic in a region always has an unique derivatives of all orders in that region.


\textit{Regular point:} Point where $f$ is analytic.\\
\textit{Singular point:} Point where $f$ is not analytic.


\subsubsection*{Cauchy-Riemann Equations}
\[\yl{
    \pdv{u}{x} = \pdv{u}{y} \quad\quad \pdv{u}{y} = - \pdv{v}{x}
}\]
Criteria for a function to be analytic in a region, derived from demanding existence of the derivative.



\holine
\subsection*{Harmonic Functions}
Harmonic functions are solutions to the \textbf{2D Laplace equation}:
\[\yl{
    \nabla^2 \phi = \pdv[2]{\phi}{x} + \pdv[2]{\phi}{y} = 0
}\]

If $f(z) = u(x,y) + iv(x,y)$ is analytic in some region, then $u(x,y)$ and $v(x,y)$ are harmonic functions.

\textbf{Theorem:} Given a harmonic function $u(x,y)$, we can always find it's \textit{harmonic conjugate} $v(x,y)$ such that $f = u + iv$ is an analytic function.


\textbf{Finding Harmonic Conjugates:} Given an harmonic function $u(x,y)$, we find it's harmonic conjugate by inserting $u(x,y)$ and $v(x,y)$ into the \textit{Cauchy-Riemann Equations}, integrating for $v$ (remember to include constants, which are only constant in regard to the integrating term), and solve for the constants to get a complete $v$.


\holine
\subsection*{Contour Integrals of Complex Functions}
\[\gr{
    \int_{C_r} (z-z_0)^n \dd{z} = \begin{cases}
    2\pi i &\text{if} \ n=-1 \\
    0 &\text{else}
    \end{cases}
}\]
where $C_r$ is a circle in positive (counter-clockwise) direction one time around the complex plane.

\subsubsection*{Upper Bound Estimate of Contour Integral}
\[\gr{
    \qty|\int_\Gamma f(z) \dd{z}| \leq M\cdot L
}\]
where $M$ is the maximum value of $f(z)$ on $\Gamma$, and $L$ is the length of $\Gamma$.

Remember the \textbf{Triangle Inequalities:}
\[
    |z_1 + z_2| \leq |z_1| + |z_2| \quad\quad |z_2 - z_1| \geq |z_2| - |z_1|
\]


\subsubsection*{Independence of Path}
If $\Gamma_1$ and $\Gamma_2$ are two contours that can be continously deformed into one another (without crossing singularities), then
\[\gr{
    \int_{\Gamma_1} f(z) \dd{z} = \int_{\Gamma_2} f(z) \dd{z}
}\]

\textbf{Cauchy's Theorem:} As a result, any contour integral that doesn't enclose a singularity, is 0, as it can be shrinked to a point.



\holine
\subsection*{Cauchy's Integral Formula}
Formula for evaluating the contour integral around a $n+1$'th order pole at $z_0$.
\[\gr{
    \int_\Gamma \frac{f(z)}{(z-z_0)^{n+1}}\dd{z} = \frac{2\pi i}{n!}f^{(n)}(z_0)
}\]
\textbf{Note:} Remember to rewrite the expression to \textit{exactly} the form above. If the contour contains several singularities, rewrite to handle each of the singularities seperately. Example, integral around $z=4$ singularity of $\cos{z}/[(z-4)(z+5)]$, rewrite to $[\cos{z}/(z+5)]/(z-4) = f(z)/(z-4)$.



\holine
\subsection*{Taylor Series}
\[
    f(z_0) = \sum_{n=0}^\infty a_n(z-z_0)^n, \quad\quad a_n = \frac{f^{(n)}(z_0)}{n!}
\]
\textbf{Theorem:} If $f(z)$ is analytic in the disk $|z-z_0| \leq R$, then the Taylor series converges for all $z$ \textit{inside} the disk.



\holine
\subsection*{Laurent Series}
We combine the \textit{Taylor} series with a \textit{Principal} series of negative powers.
\[
\yl{
    f(z_0) = \sum_{n=0}^\infty a_k(z-z_0)^n + \sum_{n=1}^\infty b_k\frac{1}{(z-z_0)^n}
}
\]
\begin{itemize}
    \item The \bll{Taylor series of positive powers converge \textit{inside}} some circle $|z-z_0| < R_2$.
    \item The \bll{Principal series of negative powers converge \textit{outside}} some circle $R_1 < |z-z_0|$.
    \item The \bll{Laurent series converges in the donut between} the two circles, $R_1 < |z-z_0| < R_2$.
\end{itemize}
\textbf{Tip:} If you only need the series to converge outside/inside some circle, \bll{you only need one of the series.}

The factor $b_0$ is called the \textbf{residue} of $f$ at $z_0$.

\subsection*{Finding Laurent Series}
If the Laurent Series should expand from a point $z_0 \neq 0$, make a substitution $\bl{w = z - z_0}$, such that the series expands from $w=0$.

\textbf{By Geometric Series:} Manipulate the function to the form
\[
    f(w) = \frac{1}{1-\eta} = \zeroinfsum \eta^n
\]
The series converges for $|\eta| < 1$
\begin{itemize}
    \item \textbf{Taylor}: inside the cirlce $(z-z_0) < R\ \Rightarrow\ \eta = (z-z_0)/R$
    \item \textbf{Principal}: outside the cirlce $(z-z_0) > R\ \Rightarrow\ \eta = R/(z-z_0)$
\end{itemize}

% \[
% \gr{
%     f(w) = C(w)\cdot \frac{1}{1-g} = \begin{cases} \ \ C(w)\sum\limits_{n=0}^\infty g^n \quad\quad \text{(Taylor)} \\ -C(w)\sum\limits_{n=1}^\infty\dfrac{1}{g^n} \quad\quad \text{(Principal)} \end{cases}
% }
% \]

\textbf{By Taylor Expansion:} If the function has no singularities, you can simply make a Taylor expansion of it. Make sure to do the substitution first.


\holine
\subsection*{Singularities and zeros}
The \textbf{order of a zero or singularity} is the \bll{number of times you must derivate the function} until the zero or infinity disapears.

Assume $f(z)$ has an isolated singularity at $z_0$, and it's Larent series is as given above.
\begin{itemize}
    \item If all $b_n = 0$, $z_0$ is a \textit{removable} singularity (not actually a singularity).
    \item If $b_n \neq 0$ for some $n$, but zero for all factors above $n$ (such that $(z-z_0)^{-n}$ is the biggest negative power), we say that $z_0$ is a \textit{pole} of order $n$.
    \item If there are infinite negative terms, we say that $z_0$ is an \textit{essential} singularity.
\end{itemize}


\holine
\subsection*{Residue Theory}
Any integral over a contour $\Gamma$ can be split up into integrals over only infinitesimally small contours around all singularities in $\Gamma$.

An contour integral containing $N$ singularities $z_k$ is given as the sum of the residues at all the singularities.

\[\yl{
    \int_\Gamma f(z) \dd{z} = 2\pi i \sum_{k=1}^N Res(f,z_k)
}\]

\subsection*{Ways of finding residues}
\begin{itemize}
    \item \textbf{\underline{Use Laurent Series} (always works):} Write out the Laurent Series of the expression around the singularities, and find the $b_1$ term (the $1/z$ coefficient).
    \item \textbf{\underline{For Simple Poles} (alt 1):} \\
    $\gr{Res(f, z_0) = \lim\limits_{z\rightarrow z_0}(z-z_0)f(z)}$\\
    \item \textbf{\underline{For Simple Poles} (alt 2):}\\
    If $f$ is a rational function $f(z) = \frac{P(z_0)}{Q(z_0)}$:\\
    $\gr{Res(f,z_0) = \frac{P(z_0)}{Q'(z_0)}}$
    \item \textbf{\underline{For Multiple Poles}:} If $f$ has a pole of order $m$ at $z_0$, and $M\geq m$, then\\
    $\gr{Res(f,z_0) = \lim\limits_{z\rightarrow z_0} \frac{1}{(M-1)!} \dv[M-1]{z}\qty[(z-z_0)^M f(z)]}$
    \\
    Naturally, if you know the order of the pole, you pick $M=m$.
\end{itemize}




% ██████╗ ███████╗ █████╗ ██╗         ██╗███╗   ██╗████████╗
% ██╔══██╗██╔════╝██╔══██╗██║         ██║████╗  ██║╚══██╔══╝
% ██████╔╝█████╗  ███████║██║         ██║██╔██╗ ██║   ██║   
% ██╔══██╗██╔══╝  ██╔══██║██║         ██║██║╚██╗██║   ██║   
% ██║  ██║███████╗██║  ██║███████╗    ██║██║ ╚████║   ██║██╗
% ╚═╝  ╚═╝╚══════╝╚═╝  ╚═╝╚══════╝    ╚═╝╚═╝  ╚═══╝   ╚═╝╚═╝

\section*{Applications to Real Integrals}
\subsection*{Type I: Trigonometric integrals over $[0, 2\pi]$}
\[\yl{
    \int_0^{2\pi} u(\cos{\theta}, \sin{\theta}) \dd{\theta}
}\]

Substitute for

\[\gr{
    \cos{\theta} = \dfrac{1}{2}\qty(z+\dfrac{1}{z}) \quad\quad \sin{\theta} = \dfrac{1}{2i}\qty(z-\dfrac{1}{z}) \quad\quad \dd{\theta} = \dfrac{\dd{z}}{iz}
}\]

The integral is now around a circular contour in the complex plane, centered around $(0,0)$ with radius $1$. Evaluate the integral by finding singularities inside the circle and solving for residues.




\holine
\subsection*{Type IIa: Rational Functions Over $[-\infty, \infty]$}
\[\yl{
    I = \int_{-\infty}^\infty f(x) \dd{x} = \int_{-\infty}^\infty \dfrac{P(x)}{Q(x)} \dd{x}
}\]

\[\gr{
    I = 2\pi i \sum Res(f, z_n)
}\]
where $z_n$ are the singularities in the \textit{upper} plane.

Works if
\begin{itemize}
    \item $degree(Q) \geq degree(P) + 2$
    \item $f$ is analytic on and above the complex plane.
\end{itemize}



\holine
\subsection*{Jordan's Lemma}
If $m>0$ is real, and $P$ and $Q$ are polynomials such that $P/Q$ is rational, and $\bl{degree(Q) \geq degree(P) + 1}$ then:
\[\gr{
    \lim\limits_{\rho\rightarrow\infty}\int\limits_{C_\rho} \frac{P(z)}{Q(z)}\exp{imz} \dd{z} = 0
}\]
where $C_\rho$ is a half-circle contour with radius $\rho$

Same holds for the lower plane if $m<0$.


\holine
\subsection*{Type IIb: ... with Trigonometric Functions}
\[\yl{
    I = \int_{-\infty}^\infty \dfrac{P(x)}{Q(x)}\cos(m x) \dd{x} \quad\quad \text{(or sin)}
}\]
\subsubsection*{Option 1}
Use complex version of sin or cos to split the integral. USE $\frac{1}{2i}$ IF SIN
\[I = \half \infint \frac{P(x)}{Q(x)}\exp{imx} \dd x + \half \infint \frac{P(x)}{Q(x)}\exp{-imx} \dd x = I_1 + I_2\]
Solve $I_1$ by close contour in upper half plane $y>0$, $I_2$ in lower half plane $y<0$.
\subsubsection*{Option 2, if $\frac{P(x)}{Q(x)}$ is real!}
Replace trig function with $\exp{imz}$, compute the contour integral in upper half plane and take the real or imaginary part at the end.


\holine
\subsection*{Type III: Singularities on the real axis (Principal Value)}
When a real integral passes singularities, we say that the integral is not defined, but it's \textbf{principal value} is. It behaves just as an ordinary integral:
\[
\yl{
    PV\int_a^b f(x) \dd{x} = \lim\limits_{r\rightarrow 0^+} \qty[\int\limits_a^{C-r} f(x) \dd{x} + \int\limits_{C+r}^b f(x) \dd{x} ]
}
\]

where $C$ is a singularity. Using the same logic as in Type II, with an added infinite half-circle on the upper plane, this evaluates to
\[
\gr{
    PV\infint f(x) \dd{x} = 2\pi i \sum_k Res(f; z_k) + \pi i \sum_j Res(f;z_j)
}
\]
where $\bl{z_k}$ are singularities in the \bll{upper half plane}, and $\bl{z_j}$ are singularities \bll{\textit{on} the real axis.}

We see that singularities on the exit contribute \textit{half} of those above.




% ██████╗ ██████╗ ███████╗
%██╔═══██╗██╔══██╗██╔════╝
%██║   ██║██║  ██║█████╗  
%██║   ██║██║  ██║██╔══╝  
%╚██████╔╝██████╔╝███████╗
% ╚═════╝ ╚═════╝ ╚══════╝
\Holine
\part*{Ordinary Differential Equations}

\subsection*{First Order, Linear, ODEs - Integrating Factor}
\[\yl{
    y'(x) + P(x) y(x) = Q(x)
}\]

\[\gr{
    y(x)\mu(x) = \int Q(x)\mu(x) \dd{x} + C} \quad\quad\text{with}\quad\quad \gr{\mu(x) = \exp{\int P(x)\dd{x}}
}\]




\Holine
\section*{Homogenous ODEs}
\[\yl{
    y'' + P(x)y' + Q(x)y = 0
}\]
\textbf{Properties}
\begin{itemize}
    \item Linear combination of solutions is also a solution
    \item General solution on form $\gr{y(x) = c_1 y_1(x) + c_2 y_2(x)}$
    \item Linearly independent solutions have a Wronskian of 0.
\end{itemize}
\[\gr{
    W(x) = 
    \begin{vmatrix} y_1(x) & y_2(x) \\ y_1'(x) & y_2'(x) \end{vmatrix}
}\]


\holine
\subsection*{Variation of the constant}
If you have \underline{one of the two linearly indepedent solutions}, you can find the other as $\gr{y_2(x) = C(x)\cdot y_1(x)}$, where $C(x)$ is a functions determined by inserting $y_2(x)$ into the ODE.

When you arrive at a solution for $C(x)$, you may discard any constants or coefficients, i.e. $C(x) = \alpha x^3 + \beta$.


\holine
\subsection*{Constant coefficients - Particular Equation}
\[\yl{
    y''(x) + ay'(x) + by(x) = 0
}\]

Solve the particular equation
\[\yl{
    \lambda^2 + a\lambda + b = 0
}\]
for $\lambda_1$ and $\lambda_2$.


\textbf{Two, real roots}
\[\gr{
    y(x) = C_1\exp{\lambda_1 x} + C_2\exp{\lambda_2 x}
}\]


\textbf{One, real root}
\[\gr{
    y(x) = (C_1 + xC_2)\exp{\lambda x}
}\]


\textbf{Two, complex roots}
\begin{equation*}
\begin{split}\gr{
    y(x) = A\exp{\lambda_1 x} + B\exp{\lambda_2 x} = \exp{-a/2 x}\qty[A\exp{i\omega x} + B\exp{-i\omega x}]} \\
    \gr{=\exp{-a/2 x}\qty[\hat{A}\cos{\omega x} + \hat{B}\sin{\omega x}]}
\end{split}
\end{equation*}


\holine
\subsection*{Euler-Cauchy Equations}
\[\yl{
    x^2y'' + a_1x y' + a_0 y = 0
}\]

Introducing
\[
    \bl{x = \exp{z}} \quad\quad\Rightarrow\quad\quad \bl{z = \ln|x|}
\]
The equation can be rewritten to
\[\yl{
    \pdv[2]{y}{z} + (a_1-1)\pdv{y}{z} + a_0 y = 0
}\]
Solve the ODE, and insert for $z$.



\holine
\subsection*{Power methods}
\begin{itemize}
    \item Represent $P(x)$ and $Q(x)$ as power series (polynomials).
    \item Assume solution on the form
    \begin{itemize}
        \item $y(x) = \sum_{n=0}^\infty a_n x^n$
        \item $y'(x) = \sum_{n=1(0)}^\infty n a_n x^{n-1}$
        \item $y''(x) = \sum_{n=2(0)}^\infty n(n-1) a_n x^{n-2}$ 
    \end{itemize}
    \item Insert back into ODE.
    \item Split into equations of matching powers of $x$.
\end{itemize}
Since we should only have two undetermined coefficients, we get one of the following:

The coefficients may be linked as a series depending on each other, like $a_{s+1} = a_s^2$. If the series are split into odd/even, two undetermined coefficients are required to describe them, so the solution is complete. Otherwise, solve the other by variation of the constant.

They may also come on a form which shows that all but two of the coefficients are zero, which gives the two linearly independent solutions from the above general solution.



\holine
\subsection*{Fröbenius method}
\[\yl{
    x^2 y'' + xb(x)y' + c(x) y = 0
}\]
Assuming solution on form
\[\gr{
    y(x) = \sum_{m=0}^\infty a_m x^{m+s}
}\]
where $s$ is some real number determined  the \textit{indicial equation}
\[\yl{
    s(s-1) + b_0s + c_0 = 0
}\]
where $b_0=b(0)$, and $c_0=c(0)$

\textbf{Three possible scenarios:}
\begin{itemize}
    \item Different roots, $s_1\neq s_2$, and $s_1-s_2\neq \text{integer}$.
    \begin{itemize}
        \item Two indepedens solutions $y_i(x) = x^{si}\sum_{m=0}^\infty a_0 x^m$
    \end{itemize}
    \item Different roots, $s_1\neq s_2$, but $s_1-s_2=\text{integer}$. ($s_1>s_2$).
    \begin{itemize}
        \item Solve for both by Power Series.
        \item Often, $s_2$ gives the complete solution (two undetermined coefficients), so try this first.
        \item Sometimes, only $s_1$ gives a solution. Find the other by variation of the constant.
    \end{itemize}
    \item Double root, $s_1 = s_2$.
    \begin{itemize}
        \item Find the solution by Power Series.
        \item Find the second solution by variation of the constant.
    \end{itemize}
\end{itemize}



\Holine
\section*{Inhomogenous ODEs}
\[
    y'' + P(x)y' + Q(x)y = R(x)
\]
\textbf{Remember} to always rewrite to this form.

\textbf{Properties}
\begin{itemize}
    \item Solutions on form\\
    $y(x) = y_h(x) + y_p(x) = c_1y_1(x) + c_2y_2(x) + y_p(x)$.
    \item $y_h(x)$ is the solution to the homogenous equation.
    \item $y_p(x)$ is \textit{any} solution to the whole ODE.
    \item Since $y_h$ contains two arbritrary constants, $y_p$ should contain none. You can discard any such constants (set them as you wish).
\end{itemize}



\holine
\subsection*{Inhomo ODEs with constant coefficients}
\[\yl{
    y'' + ay' + by = R(x)
}\]
\begin{itemize}
    \item Works if $R(x)$ has a derivative that resembles itself.
    \item Make a guess at $y_p$ with the same form as $R(x)$, with unknown coefficients.
    \item Insert back into ODE to solve for coefficients.
\end{itemize}
\textbf{Exponential:} $R(x) = A\exp{kx}$.\\
Let $\alpha$ and $\beta $ be the roots of $\lambda^2 + a\lambda + b = 0$.
\begin{enumerate}
    \item If $k\neq \alpha,\beta$: Try $y_p = C\exp{k x}$.
    \item If $k = \alpha \text{ or } \beta$: Try $y_p = Cx\exp{k x}$.
    \item If $k = \alpha = \beta$: Try $y_p = Cx^2\exp{k x}$.
\end{enumerate}

\textbf{Harmonic:} $R(x)=Asin(kx)$ or $R(x)=Acos(kx)$:
$y_{p}$ will be of the form $B\cdot sin(kx) + C\cdot cos(kx)$. Efficient to solve for $R(x)~e^{ikx}$ and take Re or Im at the end.

\textbf{Exp times poly:} $R(x)=e^{kx}\cdot P_{n}(x)$:
Try above method multiplied by a polynomial of same degree.

\holine
\subsection*{Inhomo ODEs with varying coefficients}
\[\yl{
    y'' + P(x)y' + Q(x)y = R(x)
}\]

\subsubsection*{Factorization}
If $u(x)$ is a \underline{known solution} to the homo-ODE, a particular solution is $\gr{y_p = u(x)\cdot v(x)}$ where
\[
    \gr{w' = v} \quad\quad\quad \yl{w' + \qty[\frac{2u'}{u} + P]w = \frac{R}{u}}
\]
Solve the ODE for $w$ with integrating factor.




\holine
\subsubsection*{Variation of parameters}
\[\gr{
    y_p = -y_1\int\frac{y_2R}{W}\dd{x} + y_2 \int\frac{y_1R}{W}\dd{x}
}\]
where $y_1$ and $y_2$ are known linearly indepedendent solutions to the homo-ODE.

\textbf{NOTE:} Remember that $R(x)$ is the RHS after the ODE is rewritten on the standard form.



\subsection*{Greens functions}
Let $D = \qty[ dv[2]{x} + P(x)\dv{x} + Q(x)]$ be the differential operator. Assume BC's for given $y(x)$, $y(a)$ and $y(b)$, then Greens functions will give the full solution including BC's for given D and given BC's, for \underline{any} $R(x)$.
\begin{enumerate}
\item Solution \[y(x) = \int_a^b G(x,z)R(z) \dd z \qc a \leq x, \, z \leq b\]

Conditions:
\item $D(x)G(x,z) = \delta(x-z)$, original DE with $R(x) \rightarrow \delta(x-z)$. Get two separate solutions for $x<z$ and $x>z$. $\delta(x-z) =0$ at $x=z$.
\item $G(x,z)$ must obey same BC's in x, ex ${G(a,z)=G(b,z)=0}$ if $y(a)=y(b)=0$.
\item $G(x,z)$ is continuous at $x=z$, while $\lim_{\epsilon\rightarrow0}\abs{\dv{g}{z}} = 1$ 
\end{enumerate}


\subsection*{Orthogonal Functions}
Functions on the form
\[
    p(x)y'' + p'(x)y' + \qty[q(x) + \lambda r(x)]y = 0
\]
on some interval $[a,b]$ has solutions as linear combinations of eigenfunctions $y_n(x)$ which are orthogonal with respect to $r(x)$ such that
\[
    \int_a^b r(x)y_n(x)y_m(x)^* \dd{x} = 0 \quad\quad \text{for} \lambda_n \neq \lambda{m}
\]
Any function can be written as a linear combination of these eigenfunctions
\[
    f(x) = \sum_{n=1}^\infty a_n y_n(x)
\]
then the set $\{y_n(x)\}$ is complete. The coefficients $a_n$ are determined by the orthogonality:
\[
    a_n = \int_a^b f(x)r(x)y_n(x)^* \dd{x}
\]









%███████╗ ██████╗ ██╗   ██╗██████╗ ██╗███████╗██████╗ 
%██╔════╝██╔═══██╗██║   ██║██╔══██╗██║██╔════╝██╔══██╗
%█████╗  ██║   ██║██║   ██║██████╔╝██║█████╗  ██████╔╝
%██╔══╝  ██║   ██║██║   ██║██╔══██╗██║██╔══╝  ██╔══██╗
%██║     ╚██████╔╝╚██████╔╝██║  ██║██║███████╗██║  ██║
%╚═╝      ╚═════╝  ╚═════╝ ╚═╝  ╚═╝╚═╝╚══════╝╚═╝  ╚═╝
\Holine
\part*{Fourier}
\subsection*{Usefull Shit}
\begin{itemize}
    \item recognize \textbf{odd} and \textbf{even} integrands. I.e $\infint \sin{x}/x^2 = 0$ due to odd, and $\infint\cos{x}/(1+x^2) = 2\zeroinfint\cos{x}/(1+x^2)$ due to even.
\end{itemize}

\subsection*{Orthogonality}
\[
    \int_{-\pi}^\pi \sin(mx)\sin(nx) \dd{x} = \int_{-\pi}^\pi \cos(mx)\cos(nx) \dd{x} = \pi \delta_{mn}
\]


\holine
\section*{Fourier Series}
\[
    f(x) = \half a_0 + \oneinfsum a_n\cos(\frac{n\pi x}{L}) + \oneinfsum a_n\sin(\frac{n\pi x}{L})
\]
\[
    a_n = \frac{1}{L}\int\limits_{-L}^{L}f(x) \cos(\frac{n\pi x}{L}) \dd{x} \quad\quad
    b_n = \frac{1}{L}\int\limits_{-L}^{L}f(x) \sin(\frac{n\pi x}{L}) \dd{x}
\]
\[
    f(x) = \sum_{n=-\infty}^{\infty} c_n \exp{in\pi x/L}  \quad\quad
    c_n = \frac{1}{2L}\int_{-L}^L f(x) \exp{-in\pi x/L} \dd{x}
\]

\subsection*{Even and Odd functions}
If $f(x)$ is \b{even} $\qty[f(x) = f(-x)]$:
\[
    a_n = \frac{2}{L}\int_0^L f(x)\cos(\frac{n\pi x}{L}) \dd{x} \quad\quad b_n = 0
\]
If $f(x)$ is \b{odd} $\qty[f(x) = -f(-x)]$:
\[
    a_n = 0 \quad\quad b_n = \frac{2}{L}\int_0^L f(x)\sin(\frac{n\pi x}{L}) \dd{x}
\]


\holine 
\subsection*{Dirichlet Conditions for Fourier Series}
\begin{enumerate}
    \item Finite number of min/max in interval.
    \item Finitite number of (only) finite discontinuities.
\end{enumerate}
If this holds, then the series will converge to $f(x)$ at all points. At discontinuities, the series will converge to the mid-point.
\holine
\subsection*{Parseval's Theorem}
\[
    \int_{-L}^L |f(x)|^2 \dd{x} = 2L\sum_{-\infty}^\infty |c_n|^2
\]



\holine
\section*{Fourier Transforms}
\[\gr{
    f(x) = \frac{1}{\sqrt{2\pi}} \infint F(k) \exp{ikx} \dd{k} \quad\quad
    F(k) = \frac{1}{\sqrt{2\pi}} \infint f(x) \exp{-ikx} \dd{x}
}\]

\subsection*{Odd and even functions}
If $f(x)$ is an odd function, $f(x) = -f(-x)$, the Fourier transform can be done using only sine (as cosine is symmetric around 0):
\[
    f(x) = \sqrt{\frac{2}{\pi}} i\int\limits_0^{\infty} F(k) \sin(k x) \dd{k}   \quad
    F(k) = \sqrt{\frac{2}{\pi}} i\int\limits_0^{\infty} f(x) \sin(k x) \dd{x}
\]
If $f(x)$ is even, $f(x) = f(-x)$, we need only cosine (as sine is anti-symmentric):
\[
    f(x) = \sqrt{\frac{2}{\pi}} \int\limits_0^{\infty} F(k) \cos(k x) \dd{k}   \quad
    F(k) = \sqrt{\frac{2}{\pi}} \int\limits_0^{\infty} f(x) \cos(k x) \dd{x}
\]


\subsection*{FT of a derivative}
\[
    \mathcal{F}\qty[f^{(n)}(x)] = (ik)^n \mathcal{F}\qty[f(x)]
\quad\quad
    \mathcal{F}\qty[\pdv{f}{t}(x)] = \pdv{t}\mathcal{F}\qty[f(x)]
\]

    




%██████╗ ██████╗ ███████╗
%██╔══██╗██╔══██╗██╔════╝
%██████╔╝██║  ██║█████╗  
%██╔═══╝ ██║  ██║██╔══╝  
%██║     ██████╔╝███████╗
%╚═╝     ╚═════╝ ╚══════╝
\Holine
\part*{Partial Differential Equations}
\subsection*{Notes}
\begin{itemize}
    \item In symentrical systems, it seems your can switch x<->y if it is required to suit boundary conditions (example: Diritchlet conditions are at x=a instad of at y=b).
    \item When resulting in cos/sin solutions of frequencies, include n=0 for cos, as it gives a non-zero solution, but not for sin.
\end{itemize}

\holine
\subsection*{Separation of variables}
1) The the solution function as a product of functions of each variable, i.e:
\[
    u(x,y) = X(x)Y(y) \quad\quad\quad u(r, \theta) = R(r)T(\theta)
\]
2) Insert this into the equation, and separate the equation into parts of only each variable. Each side must then be constant, and equals some \textit{separation constant}.

3) Solve each side of the equation (equaling the seperation constant), giving an infinite set of \textit{eigenfunctions}, $u_n(x,y)$ for the equation.

4) The final solution is a linear combination of the eigenfunctions.
\[
u(x,y) = \sum_{n=-\infty}^\infty c_n u_n(x,y)
\]



\holine
\subsection*{Laplace Equation - 2D Cartesian}
\[
    \nabla u(x,y) = 0
\]

Separation of variables, $u(x,y) = X(x)Y(y)$ gives solutions
\[
    u(x,y) = X(x)Y(y) = \qty{\begin{matrix} \exp{ky} \\ \exp{-ky} \end{matrix}} \times \qty{\begin{matrix} \sin(kx) \\ \cos(kx) \end{matrix}}
\]

\textbf{Diritchlet BC:} $u(x,0) = u(0,y) = u(a,y) = 0$, $u(x,b) = f(x)$
Eigenfunctions on form
\[
    u_n(x,y) = A_nF_n(x)G_n(x) = A_n\sin(n\pi x/a)\sinh(n\pi y/a)
\]


\holine
\subsection*{1D Wave Equation}
\[
    \pdv[2]{y}{x} = \frac{1}{v^2}\pdv[2]{y}{t}
\]
Seperation of variables, $u(x,t) = F(x)G(t)$ gives equations
\[
    F''(x) = -k^2F(x) \quad\quad\quad \ddot{G}(t) = -k^2v^2G(t)
\]
where the seperation constant, $-k^2$ must be negative, else the solutions would blow up.

The equations has solutions on the form
\[
    y(x,t) = \qty{\begin{matrix} \sin(kx) \\ \cos(kx) \end{matrix}} \times \qty{\begin{matrix} \sin(kvt) \\ \cos(kvt) \end{matrix}}
\]
The end-points are usually fixed at 0, leaving only the $\sin(kt)$ term, and forcing $k=n\pi/L$.

If the velocity is 0 at $t=0$, we discard the sin-velocity term and get

\[
    y(x,t) = \oneinfsum b_n\sin(\frac{n\pi x}{L})\cos(\frac{n\pi v t}{L})
\]

If position is 0 at $t=0$, we discard the cos-velocity term instead.

Initial position will be on the form
\[
    y(x,0) = \oneinfsum b_n \sin(\frac{n\pi x}{L}) = f(x)
\]
where $f(x)$ is the initial position or velocity. The coefficients $b_n$ are now Fourier coefficients, given as:
\[
    b_n = \frac{1}{2L}\int_{0}^{L} f(x)\sin(\frac{n\pi x}{L}) \dd{x}
\]



\holine
\subsection*{Heat flow equation}
General: $\frac{\partial u}{\partial t} = c^{2}\nabla^{2}u$, $\nabla^{2} = \frac{\partial^{2}}{\partial x^{2}} + \frac{\partial^{2}}{\partial y^{2}} + \frac{\partial^{2}}{\partial z^{2}}$, and $u(x,y,z,t)$.
In 1D: $\frac{\partial u}{\partial t}=c^{2}\frac{\partial^{2}u}{\partial x^{2}}$. BC: $u(0,t)=u(L,t)=0$. IC: $u(x,0)=f(x)$ 1)Sep. of variables: $\rightarrow u(x,t) = F(x)G(t)$ 
\begin{align*}
    \Rightarrow F\cdot \dot G = c^{2}F''\cdot G \Rightarrow \frac{\dot G}{c^{2}G} = \frac{F''}{F}=k (negative as before) \\
    \Rightarrow k = -p^{2} \Rightarrow F'' + p^{2}F = 0 \text{ and } \dot G + c^{2}p^{2}G=0
\end{align*}
2) Impose BCs: Exactly like 1D wave eq.: $F_{n}(x)=sin(\frac{n\pi x}{L})$, n=1,2,.. Find G(t):
\begin{align*}
    \dot G + c^{2}p_{n}^{2}G=0 \text{ or } \dot G_{n} + \lambda_{n}^{2}G_{n} = 0, \lambda_{n} = \frac{cn\pi}{L} \\
    \Rightarrow G_{n}(t) = B_{n}e^{-\lambda_{n}^{2}t} \\
    \Rightarrow \text{Eigenfunctions: } u_{n}(x,t) = B_{n}sin(\frac{n\pi x}{L})e^{-\lambda_{n}^{2}t}
\end{align*}
3) Full solution, Fourier series, implement ICs: \\
General: \(u(x,t) = \sum_{n=1}^{\infty}B_{n}sin(\frac{n\pi x}{L})e^{-\lambda_{n}^{2}t} \)\\
Initial condition: \(u(x,0)= \sum_{n=1}^{\infty}B_{n}sin(\frac{n\pi x}{L}) \overset{!}{=}f(x)\) \[\Rightarrow B_{n}=\frac{2}{L}\int_{0}^{L}f(x)sin(\frac{n\pi x}{L})dx\]

\subsection*{2D Wave eq.(Vibrating membrane)}
DE: $\frac{\partial^{2}u}{\partial t^{2}}=c^{2}\left(\frac{\partial^{2}u}{\partial x^{2}} + \frac{\partial^{2}u}{\partial y^{2}}\right)$. BCs: $u=0$ on the boundary at all times. ICs: $u(x,y,0)=f(x,y)$ and $\dot u(x,y,0)=g(x,y)$. u(x,y,t): displacement of point (x,y) on the membrane at time t. Rectangular membrane $\rightarrow$ Cartesian. Sep. of variables $\rightarrow$ Double Fourier series.
1)Sep. of variables: 3 ODE's.
Seperate out t-dependence:$u(x,y,t)=F(x,y)\cdot G(t)$ 
\begin{align*}
\Rightarrow F\cdot \ddot G = c^{2}G\left(\frac{\partial^{2}F}{\partial x^{2}}+\frac{\partial^{2}F}{\partial y^{2}}\right) \\
\Rightarrow \frac{\ddot G}{c^{2}G} = \frac{1}{F}\left(\frac{\partial^{2}F}{\partial x^{2}}+\frac{\partial^{2}F}{\partial y^{2}}\right) = -\nu^{2} \text{ (negative constant like before)} \\
\Rightarrow \ddot G + \lambda^{2}G=0; \lambda=c\cdot \nu \text{ time eq.} \\
\frac{\partial^{2}F}{\partial x^{2}}+\frac{\partial^{2}F}{\partial y^{2}} + \nu^{2}F = 0 \text{ Spatial eq.}
\end{align*}
Seperate: $F(x,y)=H(x)Q(y)$. \(\frac{d^{2}H}{dx^{2}} + k^{2}H = 0\) and \(\frac{d^{2}Q}{dy^{2}} + p^{2}H = 0\) with \(p^{2}+k^{2}=\nu^{2}\). \[\Rightarrow H(x) = Acos(kx) + Bsin(kx)\] and \[Q(y) = c\cdot cos(py) + Dsin(py)\]
2)BC's: F(x,y)=0 on the boundary: $H(0)=H(a)=Q(c)=Q(b)=0 \Rightarrow A=C=0$ and $Bsin(ka)=0\Rightarrow k=\frac{m\pi}{a}$,m integer,$Dsin(pb)=0\Rightarrow p=\frac{n\pi}{b}$,n integer. \[\Rightarrow F_{nm}(x,y)=sin(\frac{m\pi x}{a})sin(\frac{m\pi y}{b})\]
Eigenvalues: $\lambda=c\nu=c\sqrt{k^{2}+p^{2}}\Rightarrow \lambda_{mn}=c\pi\sqrt{\frac{m^{2}}{a^{2}}+\frac{n^{2}}{b^{2}}}$
From $\ddot G+\lambda^{2}G=0 \Rightarrow G_{mn}(t)=\alpha_{mn}cos(\lambda_{mn}t)+\beta_{mn}sin(\lambda_{mn}t)$ Eigenfunctions:\[u_{mn}(t)=\left[\alpha_{mn}cos(\lambda_{mn}t)+\beta_{mn}sin(\lambda_{mn}t)\right]sin(\frac{m\pi x}{a})sin(\frac{n\pi y}{b})\]
3) Full solution(with ICs) $\rightarrow$ Double Fourier series.
General solution: \(u(x,y,t)=\sum_{m,n}=u_{n}(x,y,t)\)
\[\Rightarrow \alpha_{mn}=\frac{2}{a}\cdot \frac{2}{b}\int_{0}^{a}\int_{0}^{b}f(x,y)sin(\frac{m\pi x}{a})sin(\frac{n\pi y}{b})dydx\] Find $\beta_{mn}$ from IC $\dot u$



\subsection*{Non-cartesian coordinates}
$\bullet$ General strategy for boundary value problem: Use coordinates that match the shape of the boundary.

\subsubsection*{1) Polar coordinates - Circular membrane}
$x=rcos\theta$,$y=rsin\theta$, Laplacian: \(\nabla^{2}=\frac{\partial^{2}}{\partial r^{2}}+\frac{1}{r}\frac{\partial}{\partial r}+\frac{1}{r^{2}}\frac{\partial^{2}}{\partial \theta^{2}}\) \\
$\bullet$ 2D wave eq. : \(\frac{\partial^{2}u}{\partial t^{2}} = c^{2}\left[\frac{\partial^{2}u}{\partial r^{2}}+\frac{1}{r}\frac{\partial u}{\partial r}+\frac{1}{r^{2}}\frac{\partial^{2}u}{\partial \theta^{2}}\right] \)
Simplify: Look for radially symmetric solutions, i.e. $\frac{\partial u}{\partial \theta} = 0$ 
\[\Rightarrow \frac{\partial^{2}u}{\partial t^{2}} = c^{2}\left[\frac{\partial^{2}u}{\partial r^{2}}+\frac{1}{r}\frac{\partial u}{\partial r}\right]\]
BC: $u(R,t)=0$, all $t\geq 0$. Finite at $r=0$. \\
IC: $u(r,0)=f(r)$ and $\dot u(r,0)=g(r)$ both $\theta$-independent.\\
\vspace{2mm}
1)Sep. of variables $\rightarrow$ Bessel's equation \\
$u(r,t)=w(r)\cdot G(t)$ Usual procedure \\
\(w'' + \frac{1}{r}w' k^{2}w=0\), \(\ddot G + \lambda^{2}G=0\) ($\lambda=ck$, sep.const. $-k^{2}$) \\
Set $s=k\cdot r$, so $\frac{d}{ds}=\frac{1}{k}\frac{d}{dr}$,$\frac{d^{2}}{ds^{2}}=\frac{1}{k^{2}}\frac{d^{2}}{dr^{2}}$
\[\Rightarrow \frac{d^{2}w}{ds^{2}}+\frac{1}{s}\frac{dw}{ds}+w=0 \text{ Bessel's equation with $\nu =0$} \]
General form of Bessel's:
\[s^{2}w''+sw+(s^{2}-\nu^{2})w=0\]
Solved by Fr\"obenius, tabulated solutions $J_{0}$, $Y_{0}$. \\
Finite solution at origin: $\underbrace{w=J_{0}(s)=J_{0}(kr)}_{\text{Bessel function of the first kind}}$ \\
2) BC: \\
$\bullet$ Finite at $r=0 \rightarrow$ dismissed $Y_{0}$. \\
$W(R) = J_{0}(kr)=0$. $J_{0}$ has infinitely many, irregurarly spaced, zeros $\{ \alpha_{m}\}^{m=1,2,...}$
\[\Rightarrow k=k_{m} = \frac{\alpha_{m}}{r}\Rightarrow w_{m}=J_{0}(k_{m}r)=J_{0}(\frac{\alpha_{m}}{R}r)\]
t-equation: \(G_{m}(t) = a_{m}cos(\lambda_{m}t)+b_{m}sin(\lambda_{m}t)\), where $\lambda_{m}=ck_{m}$

Eigenfunctions: 
\[u_{m}(r,t)=\left[a_{m}cos(\lambda_{m}t)+b_{m}sin(\lambda_{m}t)\right]J_{0}(k_{m}r) \text{  , m=1,2,..}\] 

3)ICs $\rightarrow$ Fourier-Bessel series \\
General solution: 
\[u(r,t) = \sum_{m=1}^{\infty}\left[ a_{m}cos(\lambda_{m}t)+b_{m}sin(\lambda_{m}t)\right]J_{0}\left(\frac{\alpha_{m}}{R}r\right)\]
t=0? \[u(r,0)=\sum_{m=1}^{\infty}a_{m}J_{0}\left(\frac{\alpha_{m}}{R}r\right)=f(r)\]
$a_{m}$ are coeffs of the Fourier-Bessel series for f(r) in term of $J_{0}\left(\frac{\alpha_{m}}{R}r\right)$
\[a_{m}=\frac{2}{R^{2}J_{1}^{2}\left(\alpha_{m}\right)}\int_{0}^{R}f(r)\cdot J_{0}\left(\frac{\alpha_{m}}{R}r\right)dr\]
Find $J_{0m}$ from $\dot u(r,0)=g(r)$

\subsubsection*{Laplace eq. in spherical coordinates, \texorpdfstring{$\nabla^{2}u=0$}{}}
\[\nabla^{2}u=\frac{1}{r^{2}}\left[\frac{\partial}{\partial r}\left(r^{2}\frac{\partial u}{\partial r}\right)+\frac{1}{sin\theta}\frac{\partial}{\partial \theta}\left(sin\theta\frac{\partial u}{\partial \theta}\right)+\frac{1}{sin^{2}\theta}\frac{\partial^{2}u}{\partial \phi^{2}}\right]=0\]
Simplify: Look for $\phi$-independent solutions, $\frac{\partial u}{\partial \phi}=0$
\[\Rightarrow \nabla^{2}u=\frac{1}{r^{2}}\left[\frac{\partial}{\partial r}\left(r^{2}\frac{\partial u}{\partial r}\right)+\frac{1}{sin\theta}\frac{\partial}{\partial \theta}\left(sin\theta\frac{\partial u}{\partial \theta}\right)\right]=0\]
BC: $u(R,\theta)=f(\theta)$. \(\lim_{r\to \infty}u(r,\theta)=0 \rightarrow\) Phsyical: finite charge. 

Seperate variables: $u(r,\theta)=G(r)H(\theta)$
\[\rightarrow \frac{1}{G}\frac{d}{dr}\left(r^{2}\frac{dG}{dr}\right)=-\frac{1}{Hsin\theta}\frac{d}{d\theta}\left(sin\theta\frac{dH}{d\theta}\right) \equiv k \]
r-equation:
\begin{align*}
    \frac{d}{dr}\left(r^{2}G'(r)\right)=kG \\
    r^{2}G'' + 2rG' -kG = 0 \\
    \text{Notation: k $\equiv$ n(n+1)} \\
    r^{2}G'' + 2rG' - n(n+1)G=0 \text{ Euler-Cauchy eq.}
\end{align*}
We use $r=e^{z}$:
\begin{align*}
    G''(z) + G(z) - n(n+1)G(z) = 0; G=e^{\lambda z}\\
    \Rightarrow \lambda^{2} + \lambda - n(n+1)=0 \\
    \Rightarrow \lambda=
    \begin{cases}
           n \\
           -(n+1) \\
    \end{cases} \\
    \Rightarrow G(r) = r^{\lambda} = 
    \begin{cases}
           r^{n} \\
           r^{-(n+1)}\\
    \end{cases}
\end{align*}
So two linearly independent solutions: 
\[G_{n}(r)=r^{n}, \widetilde G_{n}(r) = \frac{1}{r^{n+1}}\]

$\theta$-equation:
\[\frac{1}{sin\theta}\frac{d}{d\theta}\left(sin\theta\frac{dH}{d\theta}\right)+kH(\theta)=0\]
Substitute: $w=cos\theta$:
\begin{align*}
    \Rightarrow sin^{2}\theta = 1-w^{2}; \frac{d}{d\theta}=\frac{dw}{d\theta}\frac{d}{dw}=-sin\theta\frac{d}{dw} \\
    \underbrace{\frac{1}{sin\theta}\frac{d}{d\theta}}_{-\frac{d}{dw}}\underbrace{\left(sin\theta\frac{dH}{d\theta}\right)}_{-sin^{2}\theta\frac{dH}{dw}} + kH(\theta)=0 \\
    \Rightarrow \frac{d}{dw}\left[(1-w^{2})\frac{dH}{dw}\right]+kH=0 \\
    \Rightarrow \left(1-w^{2}\right)\frac{d^{2}H}{dw^{2}}-2w\frac{dH}{dw}+kH=0 \\
    \text{or } \left(1-w^{2}\right)\frac{d^{2}H}{dw^{2}}-2w\frac{dH}{dw}+n(n+1)H=0
\end{align*}
Solutions finite at $w=cost = \pm 1$ only for integer n. We want this because of physical reasons. \[\Rightarrow H(\theta) = P_{n}(w) = P_{n}(cos\theta) \text{ LEGENDRE POLYNOMIALS}\]
Eigenfunctions: \[u_{n}(r,\theta) + \widetilde u_{n}(r,\theta) = A_{n}r^{n}P_{n}(cos\theta)+\frac{B_{n}}{r^{n+1}}P_{n}(cos\theta)\]
Full solution: 
\[u(r,\theta) = \sum_{n=0}^{\infty}\left[A_{n}r^{n}+\frac{B_{n}}{r^{n+1}}\right]P_{n}(cos\theta)\]
$A_{n}$ and $B_{n}$ determined from BC's, using orthogonality relations for Legendre polynomials: 
\[\int_{-1}^{1}P_{n}(x)P_{m}(x)dx=\int_{0}^{\pi}P_{n}(cos\theta)P_{m}(cos\theta)sin\theta d\theta=\frac{2}{2n+1}\delta_{nm}\]

Example: Find electrostatic potential $u(r,\theta)$ inside and outside a sphere of radius R, when $u(R,\theta)$ ON the sphere is given.\\
\vspace{2mm}
Outside: \(u(r,\theta)\rightarrow 0 \text{ as } r\rightarrow \infty \text{ (finite charge) }\Rightarrow A_{n}=0\)
\[u(r,\theta) = \sum_{n=0}^{\infty}\frac{B_{n}}{r^{n+1}}P_{n}(cos\theta) \text{   , so   } 
u(R,\theta) = \sum_{n=0}^{\infty}\frac{B_{n}}{R^{n+1}}P_{n}(cos\theta)\]

Find $B_{n}$ from orthogonality: 
\[\int_{0}^{\pi}u(R,\theta)P_{m}(cos\theta)sin\theta d\theta = \sum_{n=0}^{\infty}\frac{B_{n}}{R^{n+1}}\cdot\frac{2}{2^{m+1}}\delta_{nm}=\frac{B_{m}}{2m+1}\cdot \frac{2}{R^{m+1}}\]
\[\Rightarrow B_{m} = \frac{R^{m+1}\left(2m+1\right)}{2}\int_{0}^{\pi}u(R,\theta)\cdot P_{m}(cos\theta)sin\theta d\theta \text{  ($u(R,\theta)$ known)} \]

Inside: $B_{n}=0$ to avoid divergence at $r=0$ (origin) \(\Rightarrow u(r,\theta)=\sum_{n=0}^{\infty}A_{n}r^{n}P_{n}(cos\theta)\).
Orthogonality gives
\[A_{m} = \frac{2m+1}{2}\frac{1}{R^{m}}\int_{0}^{\pi}u(R,\theta)P_{m}(cos\theta)sin\theta d\theta\]

\subsubsection*{Solving PDE's by Fourier Transform(FT)}
$\bullet$ FT DE wrt. one variable $\rightarrow$ ordinary DE \\
$\bullet$ Solve $\rightarrow$ find FT of the solution \\
$\bullet$ FT back \\
Example: \(a^{2}\frac{\partial^{2}u}{\partial x^{2}} = \frac{\partial u}{\partial t} \text{ with } u(x,0) = b\cdot \delta(x)\)
Use x-FT $\rightarrow$ 1st order ODE in t. \[U(k,t)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}u(x,t)e^{-ikx}dx\]
so \(\mathcal{F}\left\{\frac{\partial^{2}u}{\partial x^{2}}\right\}=-k^{2}U(k,t), \mathcal{F}\left\{\frac{\partial u}{\partial t}\right\} = \frac{\partial U(k,t)}{\partial t}\)
\[\Rightarrow \text{DE: } a^{2}(-k^{2})U(k,t)-\frac{\partial U(k,t)}{\partial t}=0 \Leftrightarrow \frac{\partial U}{\partial t}+a^{2}k^{2}U=0\]
\[\Rightarrow U(k,t)=\text{const.}\cdot e^{-k^{2}a^{2}t}=U(k,0)e^{-a^{2}k^{2}t}\]
IC: \(\mathcal{F} \left\{u(x,0)\right\} = U(k,0)=\mathcal{F}\left\{b\delta(x)\right\}=\frac{b}{\sqrt{2\pi}}\)
\[\Rightarrow U(k,t)=\frac{b}{\sqrt{2\pi}}e^{-a^{2}k^{2}t}\]
Transform back to get the original variable x:
\[u(x,t)=\frac{b}{\sqrt{2\pi}}\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{-a^{2}k^{2}t}e^{ikx}dk = \frac{b}{\sqrt{4\pi a^{2}t}}e^{-\frac{x^{2}}{4a^{2}t}}\]






\end{multicols}
\end{document}
